\chapter{Introduction}\label{ch-int}
\thispagestyle{headings}
\markboth{Chapter \ref{ch-int}: Introduction}{Chapter \ref{ch-int}: Introduction}

Suppose we want to predict some quantities of interest related to a system that
has a ``black-box'' model with
some stochastic input parameters and
some stochastic output quantities.
If the probability distributions of the input parameters are known, then we ``just'' need to
(1) explore these probability distributions and (2) propagate the uncertainties through the model.
However, it is common that we do not have a detailed quantitative knowledge of the input probability distributions to start with,
but rather just a vague idea (prior knowledge) of what they should be, augmented by some experimental data on the output quantities.
We then need first to solve a statistical inverse problem through a Bayesian approach, obtaining a more realistic representation
(posterior knowledge) of the input probability distributions before we can proceed to the steps (1) and (2) outlined before.

The purpose of this chapter is to introduce the main concepts and results necessary for
a more formal treatment of the prediction problem.
%The remainder of the Introduction is structured as follows.
Section \ref{sc-intro-prelim} reviews basic concepts on random variables, while
Section \ref{sc-intro-qoi} presents a first mathematical model of a system, as well as the applicability of Bayes' theorem to our prediction problem.
The chapter finishes with the presentation of a more detailed model of a system in Section \ref{sc-intro-detail}.

\section{Preliminary Definitions and Results}\label{sc-intro-prelim}

This section is based primarily on references \cite{Du05} and \cite{JaPr04}.

\subsection{Basic Concepts}\label{subsc-intro-prelim-basic}

Let $\Omega$ be an abstract set. A nonempty collection $U$ of subsets of $\Omega$ is called a {\it $\sigma$-algebra} of $\Omega$ if it satisfies
\begin{equation*}
B\in U \Rightarrow B^c\in U
\end{equation*}
and
\begin{equation*}
B_i\in U\mbox{ is a countable sequence of sets }\Rightarrow~\cup_iB_i\in U.
\end{equation*}
Such pair $(\Omega,U)$ is called a {\it measurable space}.

A function $\mu:U\rightarrow\mathbb{R}$ satisfying
\begin{eqnarray*}
 & & ~~(i)~\mu(\emptyset) = 0, \\
 & & ~(ii)~\mu(B)\geqslant 0\quad\forall B\in U,\mbox{ and} \\
 & & (iii)~B_i\in U\mbox{ is a countable sequence of disjoint sets}~\Rightarrow~\mu(\cup_iB_i)=\sum_i \mu(B_i),
\end{eqnarray*}
is called a {\it measure} on $(\Omega,U)$. If $\mu(\Omega)=1$ then $\mu$ is called a {\it probability measure} on $(\Omega,U)$.

Let now $(S,\mathcal{S})$ be another measurable space.
A function $Y:\Omega\rightarrow S$ is called a {\it measurable map} relative to the $\sigma$-algebras $U$ and $\mathcal{S}$ if
\begin{equation*}
Y^{-1}(B)\equiv\{\omega: Y(\omega)\in B\}\in U\quad\forall B\in\mathcal{S}.
\end{equation*}

Let $(\Omega,U)$ be a measurable space and $P:U\rightarrow [0,1]$ be a probability measure on $(\Omega,U)$.
We call the triple $(\Omega,U,P)$ a {\it probability space}.
In the context of probability spaces,
$\Omega$ is referred to as the set of {\it outcomes or samples points},
$U$ is referred to as the set of {\it events} and
a measurable map $Y:\Omega\rightarrow S$ relative to the $\sigma$-algebras $U$ and $\mathcal{S}$ is referred to as a ($U$-measurable) {\it random variable} (r.v.).

The {\it probability distribution} $P_Y:\mathcal{S}\rightarrow [0,1]$ of the $U$-measurable r.v. $Y$
is the probability measure on $(S,\mathcal{S})$ defined by
\begin{equation*}
P_Y(B) = P(Y^{-1}(B))\quad\forall B\in\mathcal{S}.
\end{equation*}
So, $(S,\mathcal{S},P_Y)$ is a probability space by itself as well.
Figure \ref{fig-rv-diagram} depicts the relationship between the main entities mentioned so far.

\begin{figure}[h]
\[
\begin{CD}
\Omega   @>Y>> S           \\
\in      @.    \in         \\
U        @.    \mathcal{S} \\
@VP VV         @VVP_Y V    \\
[0,1]    @.    [0,1]
\end{CD}
\]
\caption{Relationship between the concepts of
measurable spaces $(\Omega,U)$ and $(S,\mathcal{S})$,
probability space $(\Omega,U,P)$ with
space $\Omega$ of outcomes or sample points,
space $U$ of events and
probability measure $P$,
$U$-measurable r.v. $Y$ and
probability distribution $P_Y$ of the r.v. $Y$.
$P_Y$ is a probability measure on $(S,\mathcal{S})$ and
$(S,\mathcal{S},P_Y)$ is itself a probability space as well.
}
\label{fig-rv-diagram}
\end{figure}

Two events $A\in U$ and $B\in U$ are said to be {\it independent events} if
\begin{equation*}
P(A\cap B)=P(A)P(B).
\end{equation*}

Two $\sigma$-algebras $\mathcal{F}\subseteq U$ and $\mathcal{G}\subseteq U$ are said to be {\it independent $\sigma$-algebras} if
any two events $A\in\mathcal{F}$ and $B\in\mathcal{G}$ are independent.

We define
\begin{equation*}
\sigma(Y) = \{A\subset\Omega~:~Y^{-1}(B)=A,\mbox{ for some }B\in\mathcal{S}\}.
\end{equation*}
It is easy to check that
\begin{equation*}
\sigma(Y)\mbox{ is a }\sigma\mbox{-algebra}
\end{equation*}
and that
\begin{equation*}
\sigma(Y)\mbox{ is the smallest }\sigma\mbox{-algebra}\mbox{ that makes }Y\mbox{ a measurable map},
\end{equation*}
that is, given any $\sigma$-algebra $\mathcal{F}$ over $\Omega$, one has
\begin{equation}\label{eq-property-of-generated-sigma-alg}
Y\mbox{ is }\mathcal{F}\mbox{-measurable }\Rightarrow~\sigma(Y)\subseteq\mathcal{F}.
\end{equation}
We call $\sigma(Y)$ the $\sigma$-algebra generated by $Y$.

Given r.v.'s $Y_i:\Omega\rightarrow S$, $1\leqslant i\leqslant p$, we define
\begin{equation*}
\sigma(Y_1,\ldots,Y_p) = \{A\subset\Omega~:~Y_i^{-1}(B)=A,\mbox{ for some }B\in\mathcal{S}\mbox{ and at least one }1\leqslant i\leqslant p\}.
\end{equation*}

\subsection{$\mathbb{R}^n$ Valued Random Variables}

Throughout this manual we will assume that all r.v. are defined over the same probability space $(\Omega,U,P)$.
Also, unless otherwise specified, all r.v. will be assumed to have
$(S,\mathcal{S})=(\mathbb{R}^n,\mathfrak{B}(\mathbb{R}^n))$,
where $\mathfrak{B}(\mathbb{R}^n)$ is the Borel $\sigma$-algebra of $\mathbb{R}^n$.
We will follow the usual notation of
$Y:\Omega\rightarrow\mathbb{R}$ for a scalar r.v.,
$\mathbf{Y}:\Omega\rightarrow\mathbb{R}^n$ for a vector r.v.,
and $y=Y(\omega)$ and $\mathbf{y}=\mathbf{Y}(\omega)$ for their realizations.

We now briefly define some concepts related to a scalar r.v. $Y:\Omega\rightarrow\mathbb{R}$:
\begin{eqnarray*}
\mbox{probability distribution of }                      Y: & P_Y:  \mathfrak{B}(\mathbb{R})\rightarrow [0,1], & P_Y(B) = P(Y^{-1}(B)),       \\
\mbox{probability density (function), if it exists, of } Y: & \pi_Y:             \mathbb{R} \rightarrow [0,1], & P_Y(B) = \int_B \pi_Y(y)~dy, \\
\mbox{distribution (function) of }                       Y: & F_Y:               \mathbb{R} \rightarrow [0,1], & F_Y(y) = P_Y(Y\leqslant y).
\end{eqnarray*}
In the case of a vector r.v. $\mathbf{Y}:\Omega\rightarrow\mathbb{R}^n$, $\mathbf{Y}=(Y_0,\ldots,Y_{n-1})$,
with each $Y_i:\Omega\rightarrow\mathbb{R}$ being a scalar r.v.,$i=0,\ldots,n-1$, the respective definitions are:
\begin{eqnarray*}
 & P_{\mathbf{Y}}:  \mathfrak{B}(\mathbb{R}^n)\rightarrow [0,1], & P_{\mathbf{Y}}(B_0,\ldots,B_{n-1}) = P(Y_0^{-1}(B_0)\cap\ldots\cap Y_{n-1}^{-1}(B_{n-1})), \\
 & \pi_{\mathbf{Y}}:             \mathbb{R}^n \rightarrow [0,1], & P_{\mathbf{Y}}(\mathbf{B}) = \int_B \pi_{\mathbf{Y}}(\mathbf{y})~d\mathbf{y}, \\
 & F_{\mathbf{Y}}:               \mathbb{R}^n \rightarrow [0,1], & F_{\mathbf{Y}}(\mathbf{y}) = P_{\mathbf{Y}}(\mathbf{Y}\leqslant\mathbf{y}),
\end{eqnarray*}
where $\mathbf{Y}\leqslant\mathbf{y}$ should be interpreted in a componentwise way.
When a distinction between a scalar and a vector r.v. is not important, we will not use bold symbols, that is, we will simply use notations $Y$, $P_Y$ etc.
%Also, we will abuse notation by writing
%\begin{equation*}
%P_Y:  \mathbb{R}^n\rightarrow [0,1].
%\end{equation*}

A r.v. is called absolutely continuous if its probability distribution is absolutely continuous w.r.t. the Lebesgue measure, that is,
\begin{equation*}
m(B) = 0 \Rightarrow P_Y(B) = 0.
\end{equation*}
The Radon-Nikodym theorem \cite{KaSo05} states that
\begin{equation}\label{eq-radon-nik}
Y\mbox{ is a absolutely continuous r.v. }\Rightarrow\mbox{ its probability density }\pi_Y(\cdot)\mbox{ exists}.
\end{equation}

\subsection{Joint Probabilities}

Given two r.v. $\mathbf{Y}_1:\Omega\rightarrow\mathbb{R}^{n_1}$ and $\mathbf{Y}_2:\Omega\rightarrow\mathbb{R}^{n_2}$,
their joint probability distribution and probability density (if it exists) are defined as
\begin{eqnarray*}
P_{\mathbf{Y}_1\mathbf{Y}_2}:\mathfrak{B}(\mathbb{R}^{n_1})\times\mathfrak{B}(\mathbb{R}^{n_2})\rightarrow [0,1],~
P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,B_2)
& = &
P(\mathbf{Y}_1^{-1}(B_1)\cap\mathbf{Y}_2^{-1}(B_2)), \\
\pi_{\mathbf{Y}_1\mathbf{Y}_2}:\mathbb{R}^{n_1}\times\mathbb{R}^{n_2}\rightarrow [0,1],~
P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,B_2)
& = &
\int_{B_1}\int_{B_2}\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\mathbf{y}_1,\mathbf{y}_2)~d\mathbf{y}_2~d\mathbf{y}_1.
\end{eqnarray*}
It is worth mentioning that, in the case of a vector r.v. $\mathbf{Y}=(Y_0,\ldots,Y_{n-1})$,
the concept of probability distribution of $\mathbf{Y}$ is the same as
the concept of joint probability distribution among its components $Y_0,\ldots,Y_{n-1}$.

\subsection{Marginal Probabilities}

The marginal probability distribution and the marginal probability density (if it exists) of $\mathbf{Y}_1$ are defined as
\begin{eqnarray*}
P_{m\mathbf{Y}_1}:\mathfrak{B}(\mathbb{R}^{n_1})\rightarrow [0,1],~
P_{m\mathbf{Y}_1}(B_1)
& = &
P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,\mathbb{R}^{n_2}), \\
\pi_{m\mathbf{Y}_1}:\mathbb{R}^{n_1}\rightarrow [0,1],~
P_{m\mathbf{Y}_1}(B_1)
& = &
\int_{B_1}\pi_{m\mathbf{Y}_1}(\mathbf{y}_1)~d\mathbf{y}_1.
\end{eqnarray*}
%
If $\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\cdot,\cdot)$ exists then
\begin{equation*}
\pi_{m\mathbf{Y}_1}(\mathbf{y}_1)
=
\int_{\mathbb{R}^{n_2}}\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\mathbf{y}_1,\mathbf{y}_2)~d\mathbf{y}_2.
\end{equation*}

\subsection{Conditional Probabilities}

If $B_2\in\mathfrak{B}(\mathbb{R}^{n_2})$ is such that $P_{m\mathbf{Y}_2}(B_2)>0$, then the
conditional probability distribution of $\mathbf{Y}_1$ (conditioned) on $B_2$ is defined as
\begin{equation*}
P_{\mathbf{Y}_1|B_2}:\mathfrak{B}(\mathbb{R}^{n_1})\rightarrow [0,1],~
P_{\mathbf{Y}_1|B_2}(B_1|B_2)
=
\frac
{P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,B_2)}
{P_{m\mathbf{Y}_2}(B_2)}.
\end{equation*}
%
If $\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\cdot,\cdot)$ exists and $\mathbf{y}_2$ is such that $\pi_{m\mathbf{Y}_2}(\mathbf{y}_2)>0$, then the
conditional probability density of $\mathbf{Y}_1$ (conditioned) on $\mathbf{Y}_2=\mathbf{y}_2$ is defined as
\begin{equation*}
\pi_{\mathbf{Y}_1|\mathbf{y}_2}:\mathbb{R}^{n_1}\rightarrow [0,1],~
\pi_{\mathbf{Y}_1|\mathbf{y}_2}(\mathbf{y}_1|\mathbf{y}_2)
=
\frac
{\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\mathbf{y}_1,\mathbf{y}_2)}
{\pi_{m\mathbf{Y}_2}(\mathbf{y}_2)}.
\end{equation*}

\subsection{Bayes Theorem}

The Bayes Theorem \cite{KaSo05} states that
if $P_{Y_1|B_2}(\cdot|B_2)$ and $P_{Y_2|B_1}(\cdot|B_1)$ exist then
\begin{equation}\label{eq-Bayes-1}
P_{Y_1Y_2}(B_1,B_2) = P_{Y_1|B_2}(B_1|B_2)P_{mY_2}(B_2) = P_{Y_2|B_1}(B_2|B_1)P_{mY_1}(B_1).
\end{equation}
If $\pi_{Y_1Y_2}(\cdot,\cdot)$, $\pi_{Y_1|y_2}(\cdot|y_2)$ and $\pi_{Y_2|y_1}(\cdot|y_1)$ exist then
\begin{equation}\label{eq-Bayes-2}
\pi_{Y_1Y_2}(y_1,y_2) = \pi_{Y_1|y_2}(y_1|y_2)\pi_{mY_2}(y_2) = \pi_{Y_2|y_1}(y_2|y_1)\pi_{mY_1}(y_1).
\end{equation}

\subsection{Independence}

Two r.v. $Y_1$ and $Y_2$ are considered independent if
\begin{equation*}
P_{Y_1Y_2}(B_1,B_2) = P_{Y_1}(B_1)P_{Y_2}(B_2).
\end{equation*}
for all Borel sets $B_j$.
If $Y_1$ and $Y_2$ are independent r.v. and
their probability densities $\pi_{Y_1}$ and $\pi_{Y_2}$ exist,
then $\pi{Y_1Y_2}$ exists and is given by
\begin{equation*}
\pi_{\mathbf{Y}_1\mathbf{Y}_2}(y_1,y_2) = \pi_{Y_1}(y_1)\pi_{Y_2}(y_2),
\end{equation*}
for all points $y_j$.

It is easy to prove that
\begin{equation*}
\mbox{r.v.'s }X\mbox{ and }Y\mbox{ are independent}
~\Rightarrow~
\sigma(X)\mbox{ and }\sigma(Y)\mbox{ are independent},
\end{equation*}
and
\begin{equation*}
\left\{
\begin{array}{c}
\sigma\mbox{-algebras }\mathcal{F}\mbox{ and }\mathcal{G}\mbox{ are independent},~X\mbox{ is }\mathcal{F}\mbox{-measurable},~Y\mbox{ is }\mathcal{G}\mbox{-measurable} \\
~\Rightarrow~ \\
X\mbox{ and }Y\mbox{ are independent}.
\end{array}
\right.
\end{equation*}

A r.v. $Y:\Omega\rightarrow\mathbb{R}^n$ and a $\sigma$-algebra $\mathbf{F}$ are said to be independent if
\begin{equation}\label{eq-Y-F-independent}
P(Y^{-1}(B)\cap A) = P(Y^{-1}(B))P(A)~\forall B\in\mathfrak{B}(\mathbb{R}^n)\mbox{ and }\forall A\in\mathcal{F}.
\end{equation}

Two r.v. $Y_1$ and $Y_2$ are considered conditionally independent w.r.t. a third r.v. $\Theta$ if
\begin{equation*}
P_{Y_1Y_2|B_3}(B_1,B_2|B_3) = P_{Y_1|B_3}(B_1|B_3)P_{Y_2|B_3}(B_2|B_3).
\end{equation*}
for all Borel sets $B_1,~B_2,~B_3$ such that $P_{\Theta}(B_3)\neq 0$.

\section{Predicting Quantities of Interest of a System}\label{sc-intro-qoi}

Suppose we are studying a system model that has
some stochastic input parameters and some stochastic output quantities.
Each input parameter and each output quantity might be a r.v. or a random process
(i.e., associates a r.v. to each position in a region of space and/or to each instant in a time interval).
An input parameter might designate a coefficient, a forcing term, an initial condition or a boundary condition.
An output quantity might be a function of any combination of parameters or eventual extra variables necessary for the system description, e.g.,
the state variables presented in Section \ref{sc-intro-detail}.

If the system needs random processes for its description, we first apply space and/or time discretizations to it. 
If only r.v. originally suffice for the system description, then a discretization task is not necessary for the explanations that follow.
We then have a system with
\begin{equation}\label{eq-n-theta}
n_{\theta}\mbox{ input parameters, which are the r.v. }\Theta_i:\Omega\rightarrow\mathbb{R}^{n_i},~n_i\in\mathbb{Z}_+^*,~0\leqslant i\leqslant n_{\theta}-1,
\end{equation}
\begin{equation}\label{eq-m-y}
m_{y}\mbox{ output quantities, which are the r.v. }Y_j:\Omega\rightarrow\mathbb{R}^{m_j},~m_j\in\mathbb{Z}_+^*,~0\leqslant i\leqslant m_{y}-1,
\end{equation}
where $\mathbb{Z}_+^*$ designates the set of strictly positive integers.
Figure \ref{fig-black-box} summarizes this ``black-box'' system description.

\begin{figure}%[h]
\begin{center}
\includegraphics[scale=0.50,clip=true,viewport=0.8in 2.25in 12.0in 8.0in]{black_box.eps}
\end{center}
\caption{A generic ``black-box'' system description.
}
\label{fig-black-box}
\end{figure}

We will assume that we do not have a detailed quantitative description of the distributions of the input parameters, so that we will need to solve a statistical inverse problem
in order to obtain such distributions. 
We will suppose that
\begin{itemize}
\item there are $m_{y}$ observations $y_{j,obs}\in\mathbb{R}^{m_j}$, one for each of the output quantities,
\end{itemize}
and use the notations
\begin{eqnarray*}
\boldsymbol{\Theta} & =      & (\Theta_0,\ldots,\Theta_{n_\theta-1}), \\
\mathbf{Y}          & =      & (Y_0,     \ldots,Y_{m_y-1}          ), \\
\mathbf{y}_{obs}    & =      & (y_{0,obs}\ldots,y_{m_y-1,obs}      ), \\
N_{\theta}          & =      & \sum_{i=0}^{n_{\theta}-1}n_i,          \\
M_y                 & =      & \sum_{j=0}^{m_y       -1}m_j,          \\
R_{\theta}          & =      & \mbox{input subset of }\mathbb{R}^{N_{\theta}}\mbox{ used for model exploration}.
%\tilde{M}_{y,j}       & =      & \sum_{\substack{ k=0\\ k\neq j}}^{m_y-1} m_k,  \\
%\tilde{\mathbf{Y}}_j  & \equiv & (Y_0,\ldots,Y_{j-1},Y_{j+1},\ldots,Y_{m_y-1}), \\
%d\tilde{\mathbf{y}}_j & \equiv & dy_0\ldots dy_{j-1}dy_{j+1}\ldots dy_{m_y-1}.
\end{eqnarray*}
%\begin{eqnarray*}
%\pi_{mY_j}(y_j)       & =      & \int_{\mathbb{R}^{N_{\theta}}\times\mathbb{R}^{\tilde{M}_{y,j}}}\pi_{\boldsymbol{\Theta}\mathbf{Y}}(\boldsymbol{\theta},\mathbf{y})~d\tilde{\mathbf{y}}_j~d\boldsymbol{\theta}.
%\end{eqnarray*}

In order to be able to solve the statistical inverse problem, we will make the hypothesis that
\begin{equation}\label{eq-hyp-jpd}
\mbox{the joint probability density }\pi_{\boldsymbol{\Theta}\mathbf{Y}}:\mathbb{R}^{N_{\theta}}\times\mathbb{R}^{M_y}\rightarrow [0,1]\mbox{ exists},
\end{equation}
\begin{equation}\label{eq-hyp-obs-mp}
\mbox{the marginal probability density }\pi_{m\mathbf{Y}}(\mathbf{y}_{obs})\neq 0,
\end{equation}
and
\begin{equation}\label{eq-hyp-theta-mp}
\mbox{the marginal probability density }\pi_{m\boldsymbol{\Theta}}(\boldsymbol{\theta})\neq 0\quad\forall\boldsymbol\theta\in R_{\theta}.
\end{equation}
We emphasize that although we are assuming the existence of
$\pi_{\boldsymbol{\Theta}\mathbf{Y}}$ and
$\pi_{m\mathbf{Y}}(\mathbf{y}_{obs})$,
we will not need to know how to compute them.
Then,
\begin{equation*}
\mbox{the conditional probability }\pi_{\boldsymbol\Theta|\mathbf{y}}(\boldsymbol\theta|\mathbf{y}_{obs})\mbox{ exists }\forall\boldsymbol\theta\in\mathbb{R}^{N_\theta}
\end{equation*}
and
\begin{equation*}
\mbox{the conditional probability }\pi_{\mathbf{Y}|\boldsymbol\theta}(\mathbf{y}_{obs}|\boldsymbol\theta)\mbox{ exists }\forall\boldsymbol\theta\in R_{\theta},
\end{equation*}
that is, by Bayes theorem \eqref{eq-Bayes-2} we can claim that
\begin{equation*}
\pi_{\boldsymbol\Theta|\mathbf{y}}(\boldsymbol\theta|\mathbf{y}_{obs})
=
\frac
{\pi_{m\boldsymbol{\Theta}}(\boldsymbol{\theta})~\pi_{\mathbf{Y}|\boldsymbol\theta}(\mathbf{y}_{obs}|\boldsymbol\theta)}
{\pi_{m\mathbf{Y}}(\mathbf{y}_{obs})}
\quad\forall\boldsymbol\theta\in R_{\theta}.
\end{equation*}
This last equation defines the solution of the statistical inverse problem. In the literature terminology it is written as
\begin{equation}\label{eq-sol-sip}
\pi_{posterior}(\boldsymbol\theta)
=
\frac
{\pi_{prior}(\boldsymbol{\theta})~\ell(\mathbf{y}_{obs}|\boldsymbol\theta)}
{\pi_{m\mathbf{Y}}(\mathbf{y}_{obs})},
\end{equation}
where $\ell(\cdot|\cdot)$ stands for ``likelihood''.
However, although we can claim the existence of the solution of the statistical inverse problem,
we are still not able to compute it, since the terms on the r.h.s. in \eqref{eq-sol-sip} are not yet known.
We then assume that
\begin{equation}\label{eq-hyp-prior-known}
\mbox{the prior probability density }\pi_{prior}(\boldsymbol{\theta}),~\boldsymbol\theta\in R_{\theta},\mbox{ is known},
\end{equation}
\begin{equation}\label{eq-hyp-conditional-independence}
\mbox{the r.v. }\mathbf{Y}_j,~j=0,\ldots,m_y-1,\mbox{ are conditionally independent w.r.t. }\boldsymbol\theta,\quad\forall\boldsymbol\theta\in R_{\theta},
\end{equation}
and
\begin{equation}\label{eq-hyp-l-known}
\mbox{each individual likelihood }\ell_j(y_{j,obs}|\boldsymbol\theta),~j=0,\ldots,m_y-1,~\boldsymbol\theta\in R_{\theta},\mbox{ is known}.
\end{equation}
Although we cannot compute $\pi_{posterior}(\boldsymbol\theta)$,
since we do not have $\pi_{m\mathbf{Y}}(\mathbf{y}_{obs})$,
we can at least compute the quantity
\begin{equation}\label{eq-posterior-up2a-constant}
\tilde{\pi}(\boldsymbol\theta) =
{\pi_{prior}(\boldsymbol\theta)\prod_{j=0}^{m_y-1}\ell_j(y_{j,obs}|\boldsymbol\theta)},
\end{equation}
that is, we can at least compute the posterior joint probability density function up to a multiplicative constant.
The importance of such computation is that there exist
appropriate chain generation methods that are proved to have their limiting distributions equal 
to the target distribution $\pi_{posterior}(\boldsymbol\theta)$ as long as the target distribution is supplied
up to a multiplicative constant, such as \eqref{eq-posterior-up2a-constant}, for instance.
The generation of such chains is precisely at the heart of the so called Markov Chain Monte Carlo (MCMC) methods
an is further discussed in Chapter \ref{ch-mcmc}.

Once a chain
\begin{equation}\label{eq-markov-chain}
\{\boldsymbol{\theta}^{(0)},\boldsymbol{\theta}^{(1)},\ldots\}
\end{equation}
is (approximately) generated according to $\pi_{posterior}(\boldsymbol\theta)$ using $\tilde{\pi}(\boldsymbol\theta)$,
one can
sample parameters from the chain,
run the simulation of the system for each selected sample and
collect statistical information for any desired quantities of interest.

\section{A More Detailed System Description}\label{sc-intro-detail}

The generic ``black-box'' system description of Section \ref{sc-intro-qoi} is flexible enough to model many different situations. Indeed, the system might:
\begin{itemize}
\item be at steady-state regime, or evolve with time, from instant $t=0$ until instant $t=T$,
\item be a physical system over a bounded physical domain $D\subset\mathbb{R}^3$,
\item need $n_{s}$ stochastic state variables $S_i$ for its description, $0\leqslant i\leqslant n_{s}-1$, and
\item have equations dictating how the domain and/or the values of the parameters and/or the state values vary with time $t$ and/or space position $\mathbf{x}\in D$.
\end{itemize}
We will denote
\begin{equation*}
\mathbf{S} = (S_0,\ldots,S_{n_s-1}).
\end{equation*}

\begin{figure}%[h]
\begin{center}
\includegraphics[scale=0.50,clip=true,viewport=0.8in 2.25in 12.0in 8.0in]{black_state.eps}
\end{center}
\caption{Generic model of a system with state $\mathbf{S}(t,\mathbf{x}) = (S_0(t,\mathbf{x}),\ldots,S_{n_s-1}(t,\mathbf{x}))$
evolving from instant $t=0$ until instant $t=T$
over positions $\mathbf{x}\in D\subset\mathbb{R}^3$.
}
\label{fig-state-model}
\end{figure}
