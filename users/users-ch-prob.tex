\chapter{Probability Essentials}\label{ch-prob}
\thispagestyle{headings}
\markboth{Appendix \ref{ch-prob}: Probability Essentials}{Appendix \ref{ch-prob}: Probability Essentials}

The purpose of this chapter is to introduce the main concepts and results necessary for
a more formal treatment of the prediction problem.
It reviews basic concepts on random variables and
is based primarily on references \cite{Du05} and \cite{JaPr04}.

\section{Basic Concepts}\label{subsc-intro-prelim-basic}

Let $\Omega$ be an abstract set. A nonempty collection $U$ of subsets of $\Omega$ is called a {\it $\sigma$-algebra} of $\Omega$ if it satisfies
\begin{equation*}
B\in U \Rightarrow B^c\in U
\end{equation*}
and
\begin{equation*}
B_i\in U\text{ is a countable sequence of sets }\Rightarrow~\cup_iB_i\in U.
\end{equation*}
Such pair $(\Omega,U)$ is called a {\it measurable space}.

A function $\mu:U\rightarrow\mathbb{R}$ satisfying
\begin{eqnarray*}
 & & ~~(i)~\mu(\emptyset) = 0, \\
 & & ~(ii)~\mu(B)\geqslant 0\quad\forall B\in U,\text{ and} \\
 & & (iii)~B_i\in U\text{ is a countable sequence of disjoint sets}~\Rightarrow~\mu(\cup_iB_i)=\sum_i \mu(B_i),
\end{eqnarray*}
is called a {\it measure} on $(\Omega,U)$. If $\mu(\Omega)=1$ then $\mu$ is called a {\it probability measure} on $(\Omega,U)$.

Let now $(S,\mathcal{S})$ be another measurable space.
A function $Y:\Omega\rightarrow S$ is called a {\it measurable map} relative to the $\sigma$-algebras $U$ and $\mathcal{S}$ if
\begin{equation*}
Y^{-1}(B)\equiv\{\omega: Y(\omega)\in B\}\in U\quad\forall B\in\mathcal{S}.
\end{equation*}

Let $(\Omega,U)$ be a measurable space and $P:U\rightarrow [0,1]$ be a probability measure on $(\Omega,U)$.
We call the triple $(\Omega,U,P)$ a {\it probability space}.
In the context of probability spaces,
$\Omega$ is referred to as the set of {\it outcomes or samples points},
$U$ is referred to as the set of {\it events} and
a measurable map $Y:\Omega\rightarrow S$ relative to the $\sigma$-algebras $U$ and $\mathcal{S}$ is referred to as a ($U$-measurable) {\it random variable} (r.v.).

The {\it probability distribution} $P_Y:\mathcal{S}\rightarrow [0,1]$ of the $U$-measurable r.v. $Y$
is the probability measure on $(S,\mathcal{S})$ defined by
\begin{equation*}
P_Y(B) = P(Y^{-1}(B))\quad\forall B\in\mathcal{S}.
\end{equation*}
So, $(S,\mathcal{S},P_Y)$ is a probability space by itself as well.
Figure \ref{fig-rv-diagram} depicts the relationship between the main entities mentioned so far.

\begin{figure}[h]
\[
\begin{CD}
\Omega   @>Y>> S           \\
\in      @.    \in         \\
U        @.    \mathcal{S} \\
@VP VV         @VVP_Y V    \\
[0,1]    @.    [0,1]
\end{CD}
\]
\caption{Relationship between the concepts of
measurable spaces $(\Omega,U)$ and $(S,\mathcal{S})$,
probability space $(\Omega,U,P)$ with
space $\Omega$ of outcomes or sample points,
space $U$ of events and
probability measure $P$,
$U$-measurable r.v. $Y$ and
probability distribution $P_Y$ of the r.v. $Y$.
$P_Y$ is a probability measure on $(S,\mathcal{S})$ and
$(S,\mathcal{S},P_Y)$ is itself a probability space as well.
}
\label{fig-rv-diagram}
\end{figure}

Two events $A\in U$ and $B\in U$ are said to be {\it independent events} if
\begin{equation*}
P(A\cap B)=P(A)P(B).
\end{equation*}

Two $\sigma$-algebras $\mathcal{F}\subseteq U$ and $\mathcal{G}\subseteq U$ are said to be {\it independent $\sigma$-algebras} if
any two events $A\in\mathcal{F}$ and $B\in\mathcal{G}$ are independent.

We define
\begin{equation*}
\sigma(Y) = \{A\subset\Omega~:~Y^{-1}(B)=A,\text{ for some }B\in\mathcal{S}\}.
\end{equation*}
It is easy to check that
\begin{equation*}
\sigma(Y)\text{ is a }\sigma\text{-algebra}
\end{equation*}
and that
\begin{equation*}
\sigma(Y)\text{ is the smallest }\sigma\text{-algebra}\text{ that makes }Y\text{ a measurable map},
\end{equation*}
that is, given any $\sigma$-algebra $\mathcal{F}$ over $\Omega$, one has
\begin{equation}\label{eq-property-of-generated-sigma-alg}
Y\text{ is }\mathcal{F}\text{-measurable }\Rightarrow~\sigma(Y)\subseteq\mathcal{F}.
\end{equation}
We call $\sigma(Y)$ the $\sigma$-algebra generated by $Y$.

Given r.v.'s $Y_i:\Omega\rightarrow S$, $1\leqslant i\leqslant p$, we define
\begin{equation*}
\sigma(Y_1,\ldots,Y_p) = \{A\subset\Omega~:~Y_i^{-1}(B)=A,\text{ for some }B\in\mathcal{S}\text{ and at least one }1\leqslant i\leqslant p\}.
\end{equation*}

\section{$\mathbb{R}^n$ Valued Random Variables}

Throughout this manual we will assume that all r.v. are defined over the same probability space $(\Omega,U,P)$.
Also, unless otherwise specified, all r.v. will be assumed to have
$(S,\mathcal{S})=(\mathbb{R}^n,\mathfrak{B}(\mathbb{R}^n))$,
where $\mathfrak{B}(\mathbb{R}^n)$ is the Borel $\sigma$-algebra of $\mathbb{R}^n$.
We will follow the usual notation of
$Y:\Omega\rightarrow\mathbb{R}$ for a scalar r.v.,
$\mathbf{Y}:\Omega\rightarrow\mathbb{R}^n$ for a vector r.v.,
and $y=Y(\omega)$ and $\mathbf{y}=\mathbf{Y}(\omega)$ for their realizations.

We now briefly define some concepts related to a scalar r.v. $Y:\Omega\rightarrow\mathbb{R}$:
\begin{eqnarray*}
\text{probability distribution of }                      Y: & P_Y:  \mathfrak{B}(\mathbb{R})\rightarrow [0,1], & P_Y(B) = P(Y^{-1}(B)),       \\
\text{probability density (function), if it exists, of } Y: & \pi_Y:             \mathbb{R} \rightarrow [0,1], & P_Y(B) = \int_B \pi_Y(y)~dy, \\
\text{distribution (function) of }                       Y: & F_Y:               \mathbb{R} \rightarrow [0,1], & F_Y(y) = P_Y(Y\leqslant y).
\end{eqnarray*}
In the case of a vector r.v. $\mathbf{Y}:\Omega\rightarrow\mathbb{R}^n$, $\mathbf{Y}=(Y_1,\ldots,Y_n)$,
with each $Y_i:\Omega\rightarrow\mathbb{R}$ being a scalar r.v.,$i=1,\ldots,n$, the respective definitions are:
\begin{eqnarray*}
 & P_{\mathbf{Y}}:  \mathfrak{B}(\mathbb{R}^n)\rightarrow [0,1], & P_{\mathbf{Y}}(B_1,\ldots,B_n) = P(Y_1^{-1}(B_1)\cap\ldots\cap Y_n^{-1}(B_n)), \\
 & \pi_{\mathbf{Y}}:             \mathbb{R}^n \rightarrow [0,1], & P_{\mathbf{Y}}(\mathbf{B}) = \int_B \pi_{\mathbf{Y}}(\mathbf{y})~d\mathbf{y}, \\
 & F_{\mathbf{Y}}:               \mathbb{R}^n \rightarrow [0,1], & F_{\mathbf{Y}}(\mathbf{y}) = P_{\mathbf{Y}}(\mathbf{Y}\leqslant\mathbf{y}),
\end{eqnarray*}
where $\mathbf{Y}\leqslant\mathbf{y}$ should be interpreted in a componentwise way.
When a distinction between a scalar and a vector r.v. is not important, we will not use bold symbols, that is, we will simply use notations $Y$, $P_Y$ etc.
%Also, we will abuse notation by writing
%\begin{equation*}
%P_Y:  \mathbb{R}^n\rightarrow [0,1].
%\end{equation*}

A r.v. is called absolutely continuous if its probability distribution is absolutely continuous w.r.t. the Lebesgue measure, that is,
\begin{equation*}
m(B) = 0 \Rightarrow P_Y(B) = 0.
\end{equation*}
The Radon-Nikodym theorem \cite{KaSo05} states that
\begin{equation}\label{eq-radon-nik}
Y\text{ is a absolutely continuous r.v. }\Rightarrow\text{ its probability density }\pi_Y(\cdot)\text{ exists}.
\end{equation}

\section{Joint Probabilities}

Given two r.v. $\mathbf{Y}_1:\Omega\rightarrow\mathbb{R}^{n_1}$ and $\mathbf{Y}_2:\Omega\rightarrow\mathbb{R}^{n_2}$,
their joint probability distribution and probability density (if it exists) are defined as
\begin{eqnarray*}
P_{\mathbf{Y}_1\mathbf{Y}_2}:\mathfrak{B}(\mathbb{R}^{n_1})\times\mathfrak{B}(\mathbb{R}^{n_2})\rightarrow [0,1],~
P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,B_2)
& = &
P(\mathbf{Y}_1^{-1}(B_1)\cap\mathbf{Y}_2^{-1}(B_2)), \\
\pi_{\mathbf{Y}_1\mathbf{Y}_2}:\mathbb{R}^{n_1}\times\mathbb{R}^{n_2}\rightarrow [0,1],~
P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,B_2)
& = &
\int_{B_1}\int_{B_2}\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\mathbf{y}_1,\mathbf{y}_2)~d\mathbf{y}_2~d\mathbf{y}_1.
\end{eqnarray*}
It is worth mentioning that, in the case of a vector r.v. $\mathbf{Y}=(Y_1,\ldots,Y_n)$,
the concept of probability distribution of $\mathbf{Y}$ is the same as
the concept of joint probability distribution among its components $Y_1,\ldots,Y_n$.

\section{Marginal Probabilities}

The marginal probability distribution and the marginal probability density (if it exists) of $\mathbf{Y}_1$ are defined as
\begin{eqnarray*}
P_{m\mathbf{Y}_1}:\mathfrak{B}(\mathbb{R}^{n_1})\rightarrow [0,1],~
P_{m\mathbf{Y}_1}(B_1)
& = &
P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,\mathbb{R}^{n_2}), \\
\pi_{m\mathbf{Y}_1}:\mathbb{R}^{n_1}\rightarrow [0,1],~
P_{m\mathbf{Y}_1}(B_1)
& = &
\int_{B_1}\pi_{m\mathbf{Y}_1}(\mathbf{y}_1)~d\mathbf{y}_1.
\end{eqnarray*}
%
If $\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\cdot,\cdot)$ exists then
\begin{equation*}
\pi_{m\mathbf{Y}_1}(\mathbf{y}_1)
=
\int_{\mathbb{R}^{n_2}}\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\mathbf{y}_1,\mathbf{y}_2)~d\mathbf{y}_2.
\end{equation*}

\section{Conditional Probabilities}

If $B_2\in\mathfrak{B}(\mathbb{R}^{n_2})$ is such that $P_{m\mathbf{Y}_2}(B_2)>0$, then the
conditional probability distribution of $\mathbf{Y}_1$ (conditioned) on $B_2$ is defined as
\begin{equation*}
P_{\mathbf{Y}_1|B_2}:\mathfrak{B}(\mathbb{R}^{n_1})\rightarrow [0,1],~
P_{\mathbf{Y}_1|B_2}(B_1|B_2)
=
\frac
{P_{\mathbf{Y}_1\mathbf{Y}_2}(B_1,B_2)}
{P_{m\mathbf{Y}_2}(B_2)}.
\end{equation*}
%
If $\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\cdot,\cdot)$ exists and $\mathbf{y}_2$ is such that $\pi_{m\mathbf{Y}_2}(\mathbf{y}_2)>0$, then the
conditional probability density of $\mathbf{Y}_1$ (conditioned) on $\mathbf{Y}_2=\mathbf{y}_2$ is defined as
\begin{equation*}
\pi_{\mathbf{Y}_1|\mathbf{y}_2}:\mathbb{R}^{n_1}\rightarrow [0,1],~
\pi_{\mathbf{Y}_1|\mathbf{y}_2}(\mathbf{y}_1|\mathbf{y}_2)
=
\frac
{\pi_{\mathbf{Y}_1\mathbf{Y}_2}(\mathbf{y}_1,\mathbf{y}_2)}
{\pi_{m\mathbf{Y}_2}(\mathbf{y}_2)}.
\end{equation*}

\section{Bayes Theorem}

The Bayes Theorem \cite{KaSo05} states that
if $P_{Y_1|B_2}(\cdot|B_2)$ and $P_{Y_2|B_1}(\cdot|B_1)$ exist then
\begin{equation}\label{eq-Bayes-1}
P_{Y_1Y_2}(B_1,B_2) = P_{Y_1|B_2}(B_1|B_2)P_{mY_2}(B_2) = P_{Y_2|B_1}(B_2|B_1)P_{mY_1}(B_1).
\end{equation}
If $\pi_{Y_1Y_2}(\cdot,\cdot)$, $\pi_{Y_1|y_2}(\cdot|y_2)$ and $\pi_{Y_2|y_1}(\cdot|y_1)$ exist then
\begin{equation}\label{eq-Bayes-2}
\pi_{Y_1Y_2}(y_1,y_2) = \pi_{Y_1|y_2}(y_1|y_2)\pi_{mY_2}(y_2) = \pi_{Y_2|y_1}(y_2|y_1)\pi_{mY_1}(y_1).
\end{equation}

\section{Independence}

Two r.v. $Y_1$ and $Y_2$ are considered independent if
\begin{equation*}
P_{Y_1Y_2}(B_1,B_2) = P_{Y_1}(B_1)P_{Y_2}(B_2).
\end{equation*}
for all Borel sets $B_j$.
If $Y_1$ and $Y_2$ are independent r.v. and
their probability densities $\pi_{Y_1}$ and $\pi_{Y_2}$ exist,
then $\pi{Y_1Y_2}$ exists and is given by
\begin{equation*}
\pi_{\mathbf{Y}_1\mathbf{Y}_2}(y_1,y_2) = \pi_{Y_1}(y_1)\pi_{Y_2}(y_2),
\end{equation*}
for all points $y_j$.

It is easy to prove that
\begin{equation*}
\text{r.v.'s }X\text{ and }Y\text{ are independent}
~\Rightarrow~
\sigma(X)\text{ and }\sigma(Y)\text{ are independent},
\end{equation*}
and
\begin{equation*}
\left\{
\begin{array}{c}
\sigma\text{-algebras }\mathcal{F}\text{ and }\mathcal{G}\text{ are independent},~X\text{ is }\mathcal{F}\text{-measurable},~Y\text{ is }\mathcal{G}\text{-measurable} \\
~\Rightarrow~ \\
X\text{ and }Y\text{ are independent}.
\end{array}
\right.
\end{equation*}

A r.v. $Y:\Omega\rightarrow\mathbb{R}^n$ and a $\sigma$-algebra $\mathbf{F}$ are said to be independent if
\begin{equation}\label{eq-Y-F-independent}
P(Y^{-1}(B)\cap A) = P(Y^{-1}(B))P(A)~\forall B\in\mathfrak{B}(\mathbb{R}^n)\text{ and }\forall A\in\mathcal{F}.
\end{equation}

Two r.v. $Y_1$ and $Y_2$ are considered conditionally independent w.r.t. a third r.v. $\Theta$ if
\begin{equation*}
P_{Y_1Y_2|B_3}(B_1,B_2|B_3) = P_{Y_1|B_3}(B_1|B_3)P_{Y_2|B_3}(B_2|B_3).
\end{equation*}
for all Borel sets $B_1,~B_2,~B_3$ such that $P_{\Theta}(B_3)\neq 0$.

